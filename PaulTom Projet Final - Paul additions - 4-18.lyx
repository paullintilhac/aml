#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass extarticle
\begin_preamble
\usepackage{lastpage}

%\usepackage{tocbibind}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\minimise}{minimise}
\DeclareMathOperator*{\maximise}{maximise}
\DeclareMathOperator*{\sign}{sign}
%\usepackage{babel}

\usepackage[T1]{fontenc}
\usepackage{accanthis}
\usepackage{indentfirst}

\fancyhead{}
\fancyhead[LE,RO]{\textsl{\rightmark}}
\fancyhead[LO,RE]{\textsl{\leftmark}}
\fancyfoot{}
\fancyfoot[LE,RO]{Page \thepage\ of \pageref{LastPage}}
\fancyfoot[LO,RE]{\includegraphics[width=4cm]{NYU_logo.png}}
\renewcommand{\headrulewidth}{0.5pt}
\renewcommand{\footrulewidth}{0.5pt}

%\usepackage{fancyhdr}
%\usepackage{lastpage}
%\fancyhead{}
%\renewcommand{\headrulewidth}{0.4pt}
%\rhead{LINTILHAC AND LI}
%\lhead{CO-INTEGRATION KERNEL} 
%\fancyfoot{}
%\renewcommand{\footrulewidth}{0.4pt}
%\rfoot{\includegraphics[width=4cm]{NYU_logo.png}}
%\lfoot{Page \thepage\ of \pageref{LastPage}} 
%\renewcommand{\footrulewidth}{0.4pt}

%\usepackage{fancyhdr}
%\let\ps@plain\ps@fancy
%\fancyhf{}
%\renewcommand{\headrulewidth}{0pt}
%\rfoot{\includegraphics[width=4cm]{NYU_logo.png}}
%\fancyfoot[R]{Page \thepage\ of \pageref{LastPage}}
%\fancyfoot[L]{\includegraphics[width=4cm]{NYU_logo.png}}

\usepackage{color}
\definecolor{nyupurple}{RGB}{82,46,145}
\definecolor{matlabcomment}{rgb}{0.13,0.54,0.13}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=nyupurple,
    filecolor=nyupurple,      
    urlcolor=nyupurple,
    citecolor=nyupurple,
    hyperfootnotes=true,
}

%\usepackage{chngcntr}
%\usepackage{footmisc}
%\counterwithout{footnote}{chapter}
%\renewcommand{\thefootnote}{\fnsymbol{footnote}}
%\footnote[num]{text}
%\renewcommand\thefootnote{\textcolor{red}{\arabic{footnote}}}
%\usepackage[dvipsnames]{xcolor}
%\usepackage{alltt}
%\definecolor{string}{rgb}{0.7,0.0,0.0}
%\definecolor{comment}{rgb}{0.13,0.54,0.13}
%\definecolor{keyword}{rgb}{0.0,0.0,1.0}

\usepackage[minbibnames=1, maxbibnames=99, backend=biber,style=authoryear,dashed=false,natbib=true,url=true,bibencoding=utf8]{biblatex}
% add bibliography database
\addbibresource{bibliography.bib}
%more options
\ExecuteBibliographyOptions{sorting=nty,backref=true,doi=true}

\usepackage[section]{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\renewcommand{\thealgorithm}{\arabic{section}.\arabic{algorithm}} 
\end_preamble
\use_default_options true
\begin_modules
theorems-ams
eqs-within-sections
figs-within-sections
tabs-within-sections
theorems-sec
shapepar
enumitem
\end_modules
\maintain_unincluded_children false
\begin_local_layout
Format 60
Provides natbib 1
\end_local_layout
\language british
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command biber
\index_command default
\float_placement h
\paperfontsize 9
\spacing onehalf
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered true
\pdf_bookmarksopen true
\pdf_bookmarksopenlevel 5
\pdf_breaklinks true
\pdf_pdfborder false
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle true
\papersize a4paper
\use_geometry true
\use_package amsmath 2
\use_package amssymb 2
\use_package cancel 2
\use_package esint 2
\use_package mathdots 2
\use_package mathtools 2
\use_package mhchem 2
\use_package stackrel 2
\use_package stmaryrd 2
\use_package undertilde 2
\cite_engine natbib
\cite_engine_type authoryear
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 3cm
\topmargin 3cm
\rightmargin 3cm
\bottommargin 3cm
\footskip 1.25cm
\secnumdepth 5
\tocdepth 5
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 2
\paperpagestyle fancy
\listings_params "language=Matlab,basicstyle={\fontfamily{pcr}\selectfont\small},keywordstyle={\color{blue}},commentstyle={\color{matlabcomment}\itshape},emphstyle={\color{red}},stringstyle={\color{magenta}},identifierstyle={\color{black}},numbers=left,numberstyle={\scriptsize},breaklines=true"
\bullet 0 1 31 -1
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title

\series bold
FINAL PROJECT FOR THE COURSE ADVANCED FOUNDATIONS OF MACHINE LEARNING: ONLINE
 LEARNING OVER GRAPHS
\begin_inset Foot
status open

\begin_layout Plain Layout

\size small
\begin_inset CommandInset href
LatexCommand href
name "New York University"
target "http://www.nyu.edu"

\end_inset

 
\begin_inset CommandInset href
LatexCommand href
name "Courant Institute of Mathematical Sciences"
target "https://www.cs.nyu.edu/home/index.html"

\end_inset

.
 
\begin_inset CommandInset href
LatexCommand href
name "Spring 2017"
target "http://www.cs.nyu.edu/~mohri/aml17/"

\end_inset

.
 Professor 
\begin_inset CommandInset href
LatexCommand href
name "Mehryar Mohri"
target "http://www.cs.nyu.edu/~mohri/"

\end_inset

, Ph.D.
\end_layout

\end_inset


\end_layout

\begin_layout Author
PAUL SOPHER LINTILHAC
\begin_inset Foot
status open

\begin_layout Plain Layout
New York University 
\begin_inset CommandInset href
LatexCommand href
name "School of Engineering"
target "http://engineering.nyu.edu/academics/departments/mathematics"

\end_inset

.
 psl274@nyu.edu
\end_layout

\end_inset

 
\begin_inset Formula $\;\;$
\end_inset

AND 
\begin_inset Formula $\;$
\end_inset

THOMAS NANFENG LI
\begin_inset Foot
status open

\begin_layout Plain Layout
New York University 
\begin_inset CommandInset href
LatexCommand href
name "School of Engineering"
target "http://engineering.nyu.edu/academics/departments/mathematics"

\end_inset

.
 nl747@nyu.edu
\end_layout

\end_inset

 
\end_layout

\begin_layout Date
MAY 9
\begin_inset Formula $^{\text{TH}}$
\end_inset

, 2017
\end_layout

\begin_layout Section
Introduction to Graph
\end_layout

\begin_layout Subsection
Concepts and Definitions
\end_layout

\begin_layout Standard
We first summarise some key concepts of graph theory, for more detailed
 knowledge, we refer to 
\begin_inset CommandInset citation
LatexCommand citet
key "Bapat2014"

\end_inset

.
 A 
\begin_inset Formula $\boldsymbol{simple}$
\end_inset

 
\begin_inset Formula $\boldsymbol{graph}$
\end_inset

, that is, graph without loops and parallel edges, 
\begin_inset Formula $G\left(V,\,E\right)$
\end_inset

 consists of a finite set of 
\begin_inset Formula $\boldsymbol{vertices}$
\end_inset

 
\begin_inset Formula $V(G)$
\end_inset

 and a set of 
\begin_inset Formula $\boldsymbol{edges}$
\end_inset

 
\begin_inset Formula $E(G)$
\end_inset

 consisting of distinct, unordered pairs of vertices.
 
\begin_inset Formula $V(G)=\left\{ v_{1},\,v_{2},\,\cdots,\,v_{n}\right\} $
\end_inset

 is called the vertex set with 
\begin_inset Formula $n=\left|V(G\right|$
\end_inset

, 
\begin_inset Formula $E(G)=\left\{ e_{ij}\right\} $
\end_inset

 is called the edge set with 
\begin_inset Formula $m=\left|E(G)\right|$
\end_inset

.
 An edge 
\begin_inset Formula $e_{ij}$
\end_inset

 connects vertices 
\begin_inset Formula $v_{i}$
\end_inset

 and 
\begin_inset Formula $v_{j}$
\end_inset

 if they are 
\begin_inset Formula $\boldsymbol{adjacent}$
\end_inset

 or neighbours, which is denoted by 
\begin_inset Formula $v_{i}\sim v_{j}$
\end_inset

.
 The number of neighbours of a vertex 
\begin_inset Formula $v$
\end_inset

 is called the 
\begin_inset Formula $\boldsymbol{degree}$
\end_inset

 of 
\begin_inset Formula $v$
\end_inset

 and is denoted by 
\begin_inset Formula $d\left(v\right)$
\end_inset

, therefore, for each vertex, 
\begin_inset Formula $d\left(v_{i}\right)=\sum_{v_{i}\sim v_{j}}e_{ij}$
\end_inset

.
 If all the vertices of a graph have the same degree, the graph is 
\begin_inset Formula $\boldsymbol{regula}$
\end_inset

r, the vertices of an 
\begin_inset Formula $\boldsymbol{Eulerian}$
\end_inset

 
\begin_inset Formula $\boldsymbol{Graph}$
\end_inset

 have even degree.
 A graph is 
\begin_inset Formula $\boldsymbol{complete}$
\end_inset

 if there is an edge between every pair of vertices.
 
\end_layout

\begin_layout Standard
\begin_inset Formula $H\left(G\right)$
\end_inset

 is a 
\begin_inset Formula $\boldsymbol{sub-graph}$
\end_inset

 of 
\begin_inset Formula $G$
\end_inset

 if 
\begin_inset Formula $V(H)\subseteq V(G)$
\end_inset

 and 
\begin_inset Formula $E(H)\subseteq E(G)$
\end_inset

.
 A sub-graph 
\begin_inset Formula $H\left(G\right)$
\end_inset

 is an 
\begin_inset Formula $\boldsymbol{induced}$
\end_inset

 
\begin_inset Formula $\boldsymbol{sub-graph}$
\end_inset

 of G if two vertices of 
\begin_inset Formula $V(H)$
\end_inset

 are adjacent if and only if they are adjacent in 
\begin_inset Formula $G$
\end_inset

.
 A 
\begin_inset Formula $\boldsymbol{clique}$
\end_inset

 is a complete sub-graph of a graph.
 A 
\begin_inset Formula $\boldsymbol{path}$
\end_inset

 of 
\begin_inset Formula $k$
\end_inset

 vertices is a sequence of 
\begin_inset Formula $k$
\end_inset

 distinct vertices such that consecutive vertices are adjacent.
 A 
\begin_inset Formula $\boldsymbol{cycle}$
\end_inset

 is a connected sub-graph where every vertex has exactly two neighbours.
 A graph containing no cycles is a 
\begin_inset Formula $\boldsymbol{forest}$
\end_inset

.
 A connected forest is a 
\begin_inset Formula $\boldsymbol{tree}$
\end_inset

.
\end_layout

\begin_layout Standard
We define incidence matrix of graph.
 Let 
\begin_inset Formula $G\left(V,\,E\right)$
\end_inset

 be a graph with 
\begin_inset Formula $V(G)=\left\{ v_{1},\,v_{2},\,\cdots,\,v_{n}\right\} $
\end_inset

 and 
\begin_inset Formula $E(G)=\left\{ e_{1},\,e_{2},\,\cdots,\,e_{m}\right\} $
\end_inset

.
 Suppose each edge of 
\begin_inset Formula $G\left(V,\,E\right)$
\end_inset

 is assigned an orientation, which is arbitrary but fixed.
 The vertex-edge 
\begin_inset Formula $\boldsymbol{incidence}$
\end_inset

 
\begin_inset Formula $\boldsymbol{matrix}$
\end_inset

 of 
\begin_inset Formula $G\left(V,\,E\right)$
\end_inset

, denoted by 
\begin_inset Formula $\boldsymbol{Q}(G)$
\end_inset

, is the 
\begin_inset Formula $n\times m$
\end_inset

 matrix defined as follows.
 The rows and the columns of 
\begin_inset Formula $\boldsymbol{Q}(G)$
\end_inset

 are indexed by 
\begin_inset Formula $V(G)$
\end_inset

 and 
\begin_inset Formula $E(G)$
\end_inset

, respectively.
 The 
\begin_inset Formula $\left(i,\,j\right)$
\end_inset

 entry of 
\begin_inset Formula $\boldsymbol{Q}(G)$
\end_inset

 is 
\begin_inset Formula $0$
\end_inset

 if vertex 
\begin_inset Formula $i$
\end_inset

 and edge 
\begin_inset Formula $e_{j}$
\end_inset

 are not incident, and otherwise it is 
\begin_inset Formula $-1$
\end_inset

 or 
\begin_inset Formula $1$
\end_inset

 according as 
\begin_inset Formula $e_{j}$
\end_inset

 originates or terminates at 
\begin_inset Formula $i$
\end_inset

, respectively.
 For instance, the incidence matrix 
\begin_inset Formula $\boldsymbol{Q}(G)$
\end_inset

 of the graph that is shown in figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:1.1"

\end_inset

 is 
\begin_inset Formula 
\begin{equation}
\begin{aligned}\boldsymbol{Q}(G) & =\left[\begin{array}{cccccc}
1 & -1 & 1 & 0 & 0 & 0\\
-1 & 0 & 0 & 1 & 0 & 0\\
0 & 1 & 0 & 0 & -1 & 0\\
0 & 0 & -1 & 0 & 0 & 1\\
0 & 0 & 0 & -1 & 1 & -1
\end{array}\right]\end{aligned}
.
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename 1-1.png
	scale 61

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Example of Incidence Matrix of Graph
\begin_inset CommandInset label
LatexCommand label
name "fig:1.1"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
We introduce adjacency matrix of graph.
 Let 
\begin_inset Formula $G\left(V,\,E\right)$
\end_inset

 be a graph with 
\begin_inset Formula $V(G)=\left\{ v_{1},\,v_{2},\,\cdots,\,v_{n}\right\} $
\end_inset

 and 
\begin_inset Formula $E(G)=\left\{ e_{1},\,e_{2},\,\cdots,\,e_{m}\right\} $
\end_inset

.
 The 
\begin_inset Formula $\boldsymbol{adjacency}$
\end_inset

 
\begin_inset Formula $\boldsymbol{matrix}$
\end_inset

 of 
\begin_inset Formula $G\left(V,\,E\right)$
\end_inset

, denoted by 
\begin_inset Formula $\boldsymbol{A}(G)$
\end_inset

, is the 
\begin_inset Formula $n\times n$
\end_inset

 matrix defined as follows.
 The rows and the columns of 
\begin_inset Formula $\boldsymbol{A}(G)$
\end_inset

 are indexed by 
\begin_inset Formula $V(G)$
\end_inset

.
 If 
\begin_inset Formula $i\neq j$
\end_inset

 then the 
\begin_inset Formula $\left(i,\,j\right)$
\end_inset

 entry of 
\begin_inset Formula $\boldsymbol{A}(G)$
\end_inset

 is 
\begin_inset Formula $0$
\end_inset

 for vertices 
\begin_inset Formula $i$
\end_inset

 and 
\begin_inset Formula $j$
\end_inset

 non-adjacent, and the 
\begin_inset Formula $\left(i,\,j\right)$
\end_inset

 entry is 1 for 
\begin_inset Formula $i$
\end_inset

 and 
\begin_inset Formula $j$
\end_inset

 adjacent.
 The 
\begin_inset Formula $\left(i,\,j\right)$
\end_inset

 entry of 
\begin_inset Formula $\boldsymbol{A}(G)$
\end_inset

 is 
\begin_inset Formula $0$
\end_inset

 for 
\begin_inset Formula $i=j=1,\,\cdots\,,n$
\end_inset

.
 For instance, the adjacency matrix 
\begin_inset Formula $\boldsymbol{A}(G)$
\end_inset

 of the graph that is shown in figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:1.2"

\end_inset

 is 
\begin_inset Formula 
\begin{equation}
\begin{aligned}\boldsymbol{A}\left(G\right) & =\left[\begin{array}{ccccc}
0 & 1 & 1 & 1 & 0\\
1 & 0 & 1 & 0 & 0\\
1 & 1 & 0 & 1 & 1\\
1 & 0 & 1 & 0 & 1\\
0 & 0 & 1 & 1 & 0
\end{array}\right]\end{aligned}
.
\end{equation}

\end_inset

Clearly 
\begin_inset Formula $\boldsymbol{A}$
\end_inset

 is a symmetric matrix with zeros on the diagonal.
 The 
\begin_inset Formula $\left(i,\,j\right)$
\end_inset

 entry of 
\begin_inset Formula $\boldsymbol{A}^{k}$
\end_inset

 is the number of walks of length 
\begin_inset Formula $k$
\end_inset

 from 
\begin_inset Formula $i$
\end_inset

 to 
\begin_inset Formula $j$
\end_inset

.
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename 1-2.png
	scale 70

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Example of Incidence Matrix of Graph
\begin_inset CommandInset label
LatexCommand label
name "fig:1.2"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
We define degree matrix of graph.
 Let 
\begin_inset Formula $G\left(V,\,E\right)$
\end_inset

 be a graph with 
\begin_inset Formula $V(G)=\left\{ v_{1},\,v_{2},\,\cdots,\,v_{n}\right\} $
\end_inset

 and 
\begin_inset Formula $E(G)=\left\{ e_{1},\,e_{2},\,\cdots,\,e_{m}\right\} $
\end_inset

.
 The 
\begin_inset Formula $\boldsymbol{degree}$
\end_inset

 
\begin_inset Formula $\boldsymbol{matrix}$
\end_inset

 
\begin_inset Formula $\boldsymbol{D}(G)$
\end_inset

 for 
\begin_inset Formula $G\left(V,\,E\right)$
\end_inset

 is a 
\begin_inset Formula $n\times n$
\end_inset

 diagonal matrix defined as
\begin_inset Formula 
\[
\begin{aligned}\boldsymbol{D}\left(G\right)_{i,j} & \coloneqq\begin{cases}
d\left(v_{i}\right) & \text{if }i=j\\
0 & \text{otherwise}.
\end{cases}\end{aligned}
\]

\end_inset

According to this definition, the degree matrix of figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:1.2"

\end_inset

 is 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\begin{aligned}\boldsymbol{A}\left(G\right) & =\left[\begin{array}{ccccc}
3 & 0 & 0 & 0 & 0\\
0 & 2 & 0 & 0 & 0\\
0 & 0 & 4 & 0 & 0\\
0 & 0 & 0 & 3 & 0\\
0 & 0 & 0 & 0 & 2
\end{array}\right]\end{aligned}
.
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $\boldsymbol{Weighted}$
\end_inset

 
\begin_inset Formula $\boldsymbol{graph}$
\end_inset

 
\begin_inset Formula $G\left(V,\,E,\,W\right)$
\end_inset

 is a graph with real edge weights given by 
\begin_inset Formula $w\,:\,E\rightarrow\mathbb{R}$
\end_inset

.
 Here, the weight 
\begin_inset Formula $w\left(e\right)$
\end_inset

 of an edge 
\emph on

\begin_inset Formula $e$
\end_inset


\emph default
 indicates the similarity of the incident vertices, and a missing edge correspon
ds to zero similarity.
 The 
\begin_inset Formula $\boldsymbol{weighted}$
\end_inset

 
\begin_inset Formula $\boldsymbol{adjacency}$
\end_inset

 
\begin_inset Formula $\boldsymbol{matrix}$
\end_inset

 
\begin_inset Formula $\boldsymbol{W}\left(G\right)$
\end_inset

 of the graph 
\begin_inset Formula $G\left(V,\,E,\,W\right)$
\end_inset

 is defined by
\begin_inset Formula 
\begin{equation}
\begin{aligned}\boldsymbol{W}_{ij} & \coloneqq\begin{cases}
w\left(e\right) & \text{if }e=\left(i,\,j\right)\in E\\
0 & \text{otherwise}.
\end{cases}\end{aligned}
.
\end{equation}

\end_inset

The weight matrix 
\begin_inset Formula $\boldsymbol{W}\left(G\right)$
\end_inset

 can be, for instance, the k-nearest neighbour matrix 
\begin_inset Formula $\boldsymbol{W}\left(G\right)_{ij}=1$
\end_inset

 if and only if vertex 
\begin_inset Formula $v_{i}$
\end_inset

 is among the 
\begin_inset Formula $k$
\end_inset

-nearest neighbours of 
\begin_inset Formula $v_{j}$
\end_inset

 or vice versa, and is 0 otherwise.
 Another typical weight matrix is given by the Gaussian kernel of width
 
\begin_inset Formula $\sigma$
\end_inset


\begin_inset Formula 
\begin{equation}
\boldsymbol{W}\left(G\right)_{ij}=e^{-\frac{\left\Vert v_{i}-v_{j}\right\Vert ^{2}}{2\sigma^{2}}}.\label{eq:1.5}
\end{equation}

\end_inset

 Then the 
\begin_inset Formula $\boldsymbol{degree}$
\end_inset

 
\begin_inset Formula $\boldsymbol{matrix}$
\end_inset

 for weighted graph 
\begin_inset Formula $\boldsymbol{D}\left(G\right)$
\end_inset

 is defined by 
\begin_inset Formula 
\begin{equation}
\boldsymbol{D}\left(G\right)_{i,i}\coloneqq\sum_{j}\boldsymbol{W}\left(G\right)_{ij}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
The graph Laplacian 
\begin_inset Formula $\boldsymbol{L}\left(G\right)$
\end_inset

 is defined in two different ways.
 The 
\begin_inset Formula $\boldsymbol{normalized}$
\end_inset

 
\begin_inset Formula $\boldsymbol{graph}$
\end_inset

 
\begin_inset Formula $\boldsymbol{Laplacian}$
\end_inset

 is 
\begin_inset Formula 
\begin{equation}
\boldsymbol{L}\left(G\right)\coloneqq\boldsymbol{I}-\boldsymbol{D}^{-\frac{1}{2}}\boldsymbol{W}\boldsymbol{D}^{-\frac{1}{2}},
\end{equation}

\end_inset

and the 
\begin_inset Formula $\boldsymbol{unnormalized}$
\end_inset

 
\begin_inset Formula $\boldsymbol{graph}$
\end_inset

 
\begin_inset Formula $\boldsymbol{Laplacian}$
\end_inset

 is 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\boldsymbol{L}\left(G\right)\coloneqq\boldsymbol{D}-\boldsymbol{W}.
\end{equation}

\end_inset

Let us consider an example to understand the graph Laplacian of the graph
 that is shown in figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:1.3"

\end_inset

.
 
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename 1-3.png
	lyxscale 50
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Real-Valued Functions on a Graph
\begin_inset CommandInset label
LatexCommand label
name "fig:1.3"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset

Suppose 
\begin_inset Formula $\boldsymbol{f}\,:\,V\rightarrow\mathbb{R}$
\end_inset

 is a real-valued function on the set of the vertices of graph 
\begin_inset Formula $G\left(V,\,E\right)$
\end_inset

 such that it assigns a real number to each graph vertex.
 Therefore, 
\begin_inset Formula $\boldsymbol{f}=\left(f\left(v_{1}\right),\,f\left(v_{2}\right),\,\cdots,\,f\left(v_{n}\right)\right)^{T}\in\mathbb{R}^{n}$
\end_inset

 is a vector indexed by the vertices of graph.
 Its adjacency matrix is 
\begin_inset Formula 
\begin{equation}
\begin{aligned}\boldsymbol{A} & =\left[\begin{array}{cccc}
0 & 1 & 1 & 0\\
1 & 0 & 1 & 1\\
1 & 1 & 0 & 0\\
0 & 1 & 0 & 0
\end{array}\right].\end{aligned}
\end{equation}

\end_inset

Hence, the eigenvectors of the adjacency matrix, 
\begin_inset Formula $\boldsymbol{A}\boldsymbol{x}=\lambda\boldsymbol{x}$
\end_inset

, can be viewed as eigenfunctions 
\begin_inset Formula $\boldsymbol{A}\boldsymbol{f}=\lambda\boldsymbol{f}$
\end_inset

.
 The adjacency matrix can be viewed as an operator
\begin_inset Formula 
\begin{equation}
\begin{aligned}\boldsymbol{g} & =\boldsymbol{A}\boldsymbol{f}\\
g\left(i\right) & =\sum_{i\sim j}f\left(j\right),
\end{aligned}
\end{equation}

\end_inset

and it can also be viewed as a quadratic form
\begin_inset Formula 
\begin{equation}
\boldsymbol{f}^{T}\boldsymbol{A}\boldsymbol{f}=\sum_{e_{ij}}f\left(i\right)f\left(j\right).
\end{equation}

\end_inset

Assume that each edge in the graph have an arbitrary but fixed orientation,
 which is shown in figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:1.4"

\end_inset

.
 Then the incidence matrix of the graph is
\begin_inset Formula 
\begin{equation}
\begin{aligned}\boldsymbol{Q} & =\left[\begin{array}{cccc}
-1 & 1 & 0 & 0\\
1 & 0 & -1 & 0\\
0 & -1 & 1 & 0\\
0 & -1 & 0 & 1
\end{array}\right]\end{aligned}
.
\end{equation}

\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename 1-4.png
	lyxscale 50
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Orientation of the Graph
\begin_inset CommandInset label
LatexCommand label
name "fig:1.4"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset

 Therefore the co-boundary mapping of the graph 
\begin_inset Formula $\boldsymbol{f}\rightarrow\boldsymbol{Q}\boldsymbol{f}$
\end_inset

 implies 
\begin_inset Formula $\left(\boldsymbol{Q}\boldsymbol{f}\right)\left(e_{ij}\right)=f\left(v_{j}\right)-f\left(v_{i}\right)$
\end_inset

 is
\begin_inset Formula 
\begin{equation}
\begin{aligned}\left[\begin{array}{c}
f\left(2\right)-f\left(1\right)\\
f\left(1\right)-f\left(3\right)\\
f\left(3\right)-f\left(2\right)\\
f\left(4\right)-f\left(2\right)
\end{array}\right] & =\left[\begin{array}{cccc}
-1 & 1 & 0 & 0\\
1 & 0 & -1 & 0\\
0 & -1 & 1 & 0\\
0 & -1 & 0 & 1
\end{array}\right]\left[\begin{array}{c}
f\left(1\right)\\
f\left(2\right)\\
f\left(3\right)\\
f\left(4\right)
\end{array}\right]\end{aligned}
.
\end{equation}

\end_inset

If we let 
\begin_inset Formula 
\begin{equation}
\boldsymbol{L}=\boldsymbol{Q}^{T}\boldsymbol{Q},
\end{equation}

\end_inset

then we have 
\begin_inset Formula 
\begin{equation}
\left(\boldsymbol{L}\boldsymbol{f}\right)\left(v_{i}\right)=\sum_{v_{i}\sim v_{j}}\left[f\left(v_{i}\right)-f\left(v_{j}\right)\right].
\end{equation}

\end_inset

Hence, the connection between the Laplacian and the adjacency matrices is
 
\begin_inset Formula 
\begin{equation}
\boldsymbol{L}=\boldsymbol{D}-\boldsymbol{A}=\left[\begin{array}{cccc}
2 & -1 & -1 & 0\\
-1 & 3 & -1 & -1\\
-1 & -1 & 2 & 0\\
0 & -1 & 0 & 1
\end{array}\right],\label{eq:1.16}
\end{equation}

\end_inset

where the degree matrix 
\begin_inset Formula $\boldsymbol{D}$
\end_inset

 is 
\begin_inset Formula 
\begin{equation}
\boldsymbol{D}=\left[\begin{array}{cccc}
2 & 0 & 0 & 0\\
0 & 3 & 0 & 0\\
0 & 0 & 2 & 0\\
0 & 0 & 0 & 1
\end{array}\right].
\end{equation}

\end_inset

If we consider undirected weighted graphs, which is each edge 
\begin_inset Formula $e_{ij}$
\end_inset

 is weighted by 
\begin_inset Formula $w_{ij}$
\end_inset

, then the Laplacian as an operator is 
\begin_inset Formula 
\begin{equation}
\left(\boldsymbol{L}\boldsymbol{f}\right)\left(v_{i}\right)=\sum_{v_{i}\sim v_{j}}w_{ij}\left[f\left(v_{i}\right)-f\left(v_{j}\right)\right].
\end{equation}

\end_inset

Its quadratic form is 
\begin_inset Formula 
\begin{equation}
\boldsymbol{f}^{T}\boldsymbol{L}\boldsymbol{f}=\frac{1}{2}\sum_{e_{ij}}w_{ij}\left[f\left(v_{i}\right)-f\left(v_{j}\right)\right]^{2}.
\end{equation}

\end_inset

The intuition behind a Laplacian matrix is the following.
 If, for instance, we apply the Laplacian operator of formula 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:1.16"

\end_inset

 to the real-valued functions 
\begin_inset Formula $\boldsymbol{f}=\left(f\left(v_{1}\right),\,f\left(v_{2}\right),\,f\left(v_{3}\right),\,f\left(v_{4}\right)\right)^{T}$
\end_inset

 of the set of the vertices of graph 
\begin_inset Formula $G\left(V,\,E\right)$
\end_inset

, we have
\begin_inset Formula 
\begin{equation}
\begin{aligned}\left(\boldsymbol{L}\boldsymbol{f}\right)\left(v_{i}\right) & =\left[\begin{array}{cccc}
2 & -1 & -1 & 0\\
-1 & 3 & -1 & -1\\
-1 & -1 & 2 & 0\\
0 & -1 & 0 & 1
\end{array}\right]\left[\begin{array}{c}
f\left(v_{1}\right)\\
f\left(v_{2}\right)\\
f\left(v_{3}\right)\\
f\left(v_{4}\right)
\end{array}\right].\end{aligned}
\end{equation}

\end_inset

For simplicity, let us only look at the first element
\begin_inset Formula 
\begin{equation}
\begin{aligned}\left(\boldsymbol{L}\boldsymbol{f}\right)\left(v_{i}\right)_{1} & =\left[\begin{array}{cccc}
2 & -1 & -1 & 0\end{array}\right]\left[\begin{array}{c}
f\left(v_{1}\right)\\
f\left(v_{2}\right)\\
f\left(v_{3}\right)\\
f\left(v_{4}\right)
\end{array}\right]\\
 & =2f\left(v_{1}\right)-f\left(v_{2}\right)-f\left(v_{3}\right)\\
 & =-\left[f\left(v_{2}\right)-2f\left(v_{1}\right)+f\left(v_{3}\right)\right]\\
 & =-\left[f\left(v_{2}\right)-f\left(v_{1}\right)-f\left(v_{1}\right)+f\left(v_{3}\right)\right]
\end{aligned}
\end{equation}

\end_inset

If we label 
\begin_inset Formula $f\left(v_{1}\right)=f_{k}$
\end_inset

, 
\begin_inset Formula $f\left(v_{2}\right)=f_{k+1}$
\end_inset

, and 
\begin_inset Formula $f\left(v_{3}\right)=f_{k-1}$
\end_inset

, then we have
\begin_inset Formula 
\begin{equation}
\left(\boldsymbol{L}\boldsymbol{f}\right)\left(v_{i}\right)_{1}=-\left[f_{k+1}-2f_{k}+f_{k-1}\right].
\end{equation}

\end_inset

We recall that the second order derivative can be approximated by
\begin_inset Formula 
\begin{equation}
\begin{aligned}f^{''}\left(x\right) & =\frac{\frac{f\left(x+\Delta x\right)-f\left(x\right)}{\Delta x}-\frac{f\left(x\right)-f\left(x-\Delta x\right)}{\Delta x}}{\Delta x}\\
 & =\frac{f\left(x+\Delta x\right)-2f\left(x\right)+f\left(x-\Delta x\right)}{\left(\Delta x\right)^{2}}.
\end{aligned}
\end{equation}

\end_inset

Hence, we observe that the graph Laplacian is the negative numerator of
 the finite difference approximation of the second derivative.
 The Laplacian matrix 
\begin_inset Formula $\boldsymbol{L}$
\end_inset

 is symmetric and positive semi-definite, and it has 
\begin_inset Formula $n$
\end_inset

 non-negative, real-valued eigenvalues 
\begin_inset Formula $0=\lambda_{1}\leq\lambda_{2}\leq\cdots\leq\lambda_{n}$
\end_inset

.
 The number of 0 eigenvalues of the Laplacian matrix 
\begin_inset Formula $\boldsymbol{L}$
\end_inset

 is the number of connected components, because each connected component
 forms a block in the Laplacian matrix that only has edges within itself,
 and each block is the Laplacian for a small connected component and it
 has one zero eigenvalue, so the number of zeros is the number of blocks
 is the number of connected components.
\end_layout

\begin_layout Subsection
Basic Idea for Semi-Supervised Learning over Graphs
\end_layout

\begin_layout Standard
The common denominator of semi-supervised learning algorithms over graphs
 is that the data are represented by the vertices of a graph, the edges
 of which are labelled with the pairwise distances of the incident vertices,
 and a missing edge corresponds to infinite distance.
 Most graph methods refer to the graph by utilizing the graph Laplacian.
 
\end_layout

\begin_layout Standard
Given the graph 
\begin_inset Formula $G\left(V,\,E,\,W\right)$
\end_inset

, a simple idea for semi-supervised learning label propagation is to propagate
 labels on the graph.
 Starting with vertices 
\begin_inset Formula $1,\,2,\,\cdots,\,l$
\end_inset

 labelled 
\begin_inset Formula $l$
\end_inset

 with their known label
\begin_inset Formula $1$
\end_inset

 or 
\begin_inset Formula $−1$
\end_inset

 and nodes 
\begin_inset Formula $l+1,\,\cdots,\,n$
\end_inset

 labelled with 
\begin_inset Formula $0$
\end_inset

, each vertex starts to propagate its label to its neighbours, and the process
 is repeated until convergence.
 
\begin_inset CommandInset citation
LatexCommand citet
key "BengioDelalleauRoux2006"

\end_inset

 proposed a label propagation scheme based on the Jacobi iterative method
 for linear systems.
 Estimated labels on both labelled and unlabelled data are denoted by 
\begin_inset Formula $\hat{\boldsymbol{Y}}=\left(\hat{\boldsymbol{Y}}_{l},\,\hat{\boldsymbol{Y}}_{u}\right)$
\end_inset

, where where 
\begin_inset Formula $\hat{\boldsymbol{Y}}_{l}$
\end_inset

 may be allowed to differ from the given labels 
\begin_inset Formula $\boldsymbol{Y}_{l}=\left(y_{1},\,y_{2},\,\cdots,\,y_{l}\right)$
\end_inset

.
 It uses an additional regularization term 
\begin_inset Formula $\epsilon$
\end_inset

 for better numerical stability, which is shown in algorithm 
\begin_inset CommandInset ref
LatexCommand ref
reference "alg:1.1"

\end_inset

.
 
\begin_inset Float algorithm
wide false
sideways false
status open

\begin_layout Plain Layout
Compute weight matrix 
\begin_inset Formula $\boldsymbol{W}$
\end_inset

 from formula 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:1.5"

\end_inset

 such that 
\begin_inset Formula $\boldsymbol{W}_{ii}=0$
\end_inset


\end_layout

\begin_layout Plain Layout
Compute the diagonal degree matrix 
\begin_inset Formula $\boldsymbol{D}$
\end_inset

 by 
\begin_inset Formula $\boldsymbol{D}_{ii}=\sum_{j}\boldsymbol{W}_{ij}$
\end_inset

 
\end_layout

\begin_layout Plain Layout
Choose a parameter 
\begin_inset Formula $\alpha\in\left(0,\,1\right)$
\end_inset

 and a small 
\begin_inset Formula $\epsilon>0$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Formula $\mu=\frac{\alpha}{1-\alpha}\in\left(0,\,+\infty\right)$
\end_inset


\end_layout

\begin_layout Plain Layout
Compute the diagonal matrix 
\begin_inset Formula $\boldsymbol{A}$
\end_inset

 by 
\begin_inset Formula $\boldsymbol{A}_{ii}=\boldsymbol{I}_{l}\left(i\right)+\mu\boldsymbol{D}_{ii}+\mu\epsilon$
\end_inset


\end_layout

\begin_layout Plain Layout
Initialize 
\begin_inset Formula $\hat{\boldsymbol{Y}}^{\left(0\right)}=\left(y_{1},\,y_{2},\,\cdots,\,y_{l},\,0,\,0,\,\cdots,\,0\right)$
\end_inset


\end_layout

\begin_layout Plain Layout
Iterate
\end_layout

\begin_layout Plain Layout
\begin_inset Formula $\qquad$
\end_inset


\begin_inset Formula $\hat{\boldsymbol{Y}}^{\left(t+1\right)}=\boldsymbol{A}^{-1}\left(\mu\boldsymbol{W}\hat{\boldsymbol{Y}}^{\left(t\right)}+\hat{\boldsymbol{Y}}^{\left(0\right)}\right)$
\end_inset


\end_layout

\begin_layout Plain Layout
until convergence to 
\begin_inset Formula $\hat{\boldsymbol{Y}}^{\left(\infty\right)}$
\end_inset


\end_layout

\begin_layout Plain Layout
Label point 
\begin_inset Formula $v_{i}$
\end_inset

 by the sign of 
\begin_inset Formula $\hat{y}_{i}^{\left(\infty\right)}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Jacobi Iterative Label Propagation Algorithm
\begin_inset CommandInset label
LatexCommand label
name "alg:1.1"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand citet
key "ZhouBousquetLalWS2004"

\end_inset

 proposed a similar label propagation algorithm, see algorithm 
\begin_inset CommandInset ref
LatexCommand ref
reference "alg:1.2"

\end_inset

, that uses graph Laplacian.
 At each step a vertex 
\begin_inset Formula $i$
\end_inset

 receives a contribution from its neighbours 
\begin_inset Formula $j$
\end_inset

 and an additional small contribution given by its initial value.
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
wide false
sideways false
status open

\begin_layout Plain Layout
Compute weight matrix 
\begin_inset Formula $\boldsymbol{W}$
\end_inset

 from formula 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:1.5"

\end_inset

 for 
\begin_inset Formula $i\ne j$
\end_inset

 and 
\begin_inset Formula $\boldsymbol{W}_{ii}=0$
\end_inset


\end_layout

\begin_layout Plain Layout
Compute the diagonal degree matrix 
\begin_inset Formula $\boldsymbol{D}$
\end_inset

 by 
\begin_inset Formula $\boldsymbol{D}_{ii}=\sum_{j}\boldsymbol{W}_{ij}$
\end_inset

 
\end_layout

\begin_layout Plain Layout
Compute the normalized graph Laplacian 
\begin_inset Formula $\boldsymbol{L}=\boldsymbol{D}^{-\frac{1}{2}}\boldsymbol{W}\boldsymbol{D}^{-\frac{1}{2}}$
\end_inset


\end_layout

\begin_layout Plain Layout
Initialize 
\begin_inset Formula $\hat{\boldsymbol{Y}}^{\left(0\right)}=\left(y_{1},\,y_{2},\,\cdots,\,y_{l},\,0,\,0,\,\cdots,\,0\right)$
\end_inset


\end_layout

\begin_layout Plain Layout
Choose a parameter 
\begin_inset Formula $\alpha\in\left[0,\,1\right]$
\end_inset

 
\end_layout

\begin_layout Plain Layout
Iterate
\end_layout

\begin_layout Plain Layout
\begin_inset Formula $\qquad$
\end_inset


\begin_inset Formula $\hat{\boldsymbol{Y}}^{\left(t+1\right)}=\alpha\boldsymbol{L}\hat{\boldsymbol{Y}}^{\left(t\right)}+\left(1-\alpha\right)\hat{\boldsymbol{Y}}^{\left(0\right)}$
\end_inset


\end_layout

\begin_layout Plain Layout
until convergence to 
\begin_inset Formula $\hat{\boldsymbol{Y}}^{\left(\infty\right)}$
\end_inset


\end_layout

\begin_layout Plain Layout
Label point 
\begin_inset Formula $v_{i}$
\end_inset

 by the sign of 
\begin_inset Formula $\hat{y}_{i}^{\left(\infty\right)}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Graph Laplacian Label Propagation Algorithm 
\begin_inset CommandInset label
LatexCommand label
name "alg:1.2"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
A different approach was proposed by Herbster (2011) using projection and
 kernel methods.
 The method uses minimal norm interpolation, which I will later explain
 can be thought of as finding the distribution over the vertices that minimizes
 the total flux induced over the graph, under the constraint that the labeled
 points are approximately correct.
\end_layout

\begin_layout Standard
A key object in this approach is the pseudoinverse of the graph Laplacian.
 $L^+$ can be thought of as the reproducing kernel of a particular Hilbert
 space H of real-valued functions over the vertices of the graph: $$f: V
 -> R^n$$ equipped with the inner product $$<f,g>=f^TLg.$$ Over the entire
 Vector space of real-valued functions on the graph, <f,g> is only a semi-inner
 product, and therefore induces the semi-norm $||g||$.
 If $f^*$ is an eigenvector of L corresponding to an eigenvalue of 0, then
 $<f^*,f^*>=0$.
 These eignevectors with eigenvalues of zero are precisely the eigenvectors
 that are piecewise constant.
 We can see this by noting that 
\end_layout

\begin_layout Standard
Claim: 
\end_layout

\begin_layout Standard
$$||g||=
\backslash
sum_{i,j 
\backslash
in E}{n}(g_i-g_j)^2$$.
\end_layout

\begin_layout Standard
Proof:
\end_layout

\begin_layout Standard
$$||g||=<g,g>=
\backslash
sum_{i,j=1}{n}g_iL_{ij}g_j=
\backslash
sum_{i=j}{n}g_iL_{ij}g_j+
\backslash
sum{i
\backslash
neqj}{n}g_iL_{ij}g_j$$
\end_layout

\begin_layout Standard
Noting that the diagonal component of $L$ is simply $D$ and the off-diagonal
 is $-A$, we can re-write this as 
\end_layout

\begin_layout Standard
$$
\backslash
sum_{i=1}{n}g_i^2D_{ii}-
\backslash
sum{i
\backslash
neq j}{n}g_iA_{ij}g_j$$
\end_layout

\begin_layout Standard
$D_ii$ is defined as $$D_ii=
\backslash
sum_{j=1}{n}A_{ij}$$, so we have
\end_layout

\begin_layout Standard
$$||g||=
\backslash
sum_{i,j=1}{n}g_i^2A_{ij}-
\backslash
sum{i
\backslash
neq j}{n}g_iA_{ij}g_j$$
\end_layout

\begin_layout Standard
$$=
\backslash
sum_{i,j 
\backslash
in E}{n}g_i^2-2g_ig_j$$
\end_layout

\begin_layout Standard
Where we have picked up a factor of 2 from the second summation since $E
 is the set of unordered pairs in the edge set, and therefore each edge
 gets counted twice.
 Finally
\end_layout

\begin_layout Standard
$$||g||=
\backslash
sum_{i,j 
\backslash
in E}{n}(g_i-g_j)^2$$
\end_layout

\begin_layout Standard
As we can see, the sum vanishes if $g_i=g_j$ for all vertices connected
 by an edge, i.e.
 when g is piecewise constant on each connected component.
 Therefore we must restrict our functions to be in the subspace of H spanned
 by the eigenvectors that have non-zero eigenvalues.
 Restricted to this subspace, $<f,g>$ is indeed an inner product, and therefore
 induces a true norm $||g||$.
 Since H is a Hilbert space, we can use the Riesz Representation theorem
 to conclude that the evaluation functional of f at any vertex, $f(v_i)$,
 being a linear functional ($(f+g)(v_i)=(f+g)_i(v)= f_i(v)+g_i(v)=f(v_i)+g(v_i)$
), can be represented as an inner product: $$f(v_i)=<K_i,f>=K_iLf.$$ The
 pseudoinverse $L^+$ satisfies this property, which can be verified by noting
 that $$f_i=L^+_iLf_i.$$ Thus $L^+$ is the reproducing kernel of H.
\end_layout

\begin_layout Standard
We can get more intuition about the basic objects such as $||g||$ and $L^+$
 by using the concept of conductance (it is no coincidence that the continuous
 version of the Laplacian appears in the heat equation).
 If we think of f as some distribution over the nodes, we can think of $Lf$
 roughly as the flux induced at each of the nodes by that distribution over
 the graph.
 Then the form $g^TLf$ represents some weighted measurement of this flux
 with the weights given by g.
 For example, if f is a binary vector representing the boundary of some
 open set on the graph $<f,g>$ would be the flux produced by g as measured
 on the boundary represented by f.
 We can even use this formalism to quickly prove a version of 
\begin_inset Quotes eld
\end_inset

Stokes' Theorem
\begin_inset Quotes erd
\end_inset

 on graphs.
\end_layout

\begin_layout Standard
Claim:
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $G\left(V,\,E,\,W\right)$
\end_inset

 be a graph imbued with the topology generated by the open neighborhoods
 $N_i={v_j : (i,j)
\backslash
in E}$.
 Suppose we have some subset $U 
\backslash
subset V$.
 Then we can define the boundary of U as the set of all vertices contained
 in the closure of U but not contained in U iteself: $
\backslash
partial U 
\backslash
def {v_j : v_j 
\backslash
in 
\backslash
bar{U}-U}$.
 Now suppose our vertices V are ordered such that $v_1,...,v_k 
\backslash
in U$, $v_{k+1},...,v_l 
\backslash
in 
\backslash
partial U$, $v_{l+1},...,v_n 
\backslash
in V-
\backslash
bar{U}$.
 Now let $1_U $ be a binary vector with all 1's for the first k entries,
 and 0's elsewhere, and let $1_{
\backslash
partial U} be the binary vector with all 1's for entries k+1 through l,
 and zeros elsewhere.
 Then according to the above interpretation of the norm, $F_U 
\backslash
def 1_U L g$ is the total flux induced by distribution g over the interior
 of U, while $F_{
\backslash
partial U} 
\backslash
def 1_{
\backslash
partial U} L g$ is the total flux induced by g as measured over the boundary
 of U.
 Our claim is that $F_U = - F_{
\backslash
partial U}$.
\end_layout

\begin_layout Standard
Proof:
\end_layout

\begin_layout Standard
Let us denote by $d_i$ the degree of vertex i, $d^{int}_i$ by the number
 of edges connecting vertex i to points in U, and $d^{ext}_i$ by the number
 of edges connecting vertex i to points not in U, so that $d_i=d^{int}_i+d^{ext}
_i$.
 In particular, for any $v_i 
\backslash
in U, d^{ext}_i$ is the number of edges connecting $v_i$ to points in $
\backslash
partial U$, since by definition all other vertices are not connected to
 $v_i$.
 Then for the LHS, note that the only contribution to the i-th entry is
 given by the first k columns of $L$, and a straighforward calculation shows
 $$1_U L g = 
\backslash
sum_{i 
\backslash
in U} (d_i-d^{int}_i)=
\backslash
sum_{i 
\backslash
in U} d^{ext}.$$ For the RHS, we can see that the only contribution to the
 sum is from entries k+1 to l, which another straightforward calculation
 shows $$1_{
\backslash
partial U} L g = 
\backslash
sum{i 
\backslash
in 
\backslash
partial U} d^{ext}_i.$$.
 
\end_layout

\begin_layout Standard
Thus, $1_U L g =- 1_{
\backslash
partial U} L g 
\backslash
forall g 
\backslash
in H.$$ 
\end_layout

\begin_layout Standard
Despite the simplicity of the proof and the fact that there is a very general
 form of Stoke's theorem over smooth manifolds, this graphical version of
 Stokes' theorem has not been seen by the authors, and could potentially
 be leveraged for new graphical algorithms.
\end_layout

\begin_layout Standard
To gain intuition about $L^+$, we turn back to the representer theorem,
 namely that $f(v_i)=L^+_iLf$.
 In the heat analogy, this could be interpreted as saying that the heat
 at each vertex can be expressed in terms of, or derived from, the flux
 through every vertex.
 So in this heat analogy, L sends a heat distribution $f$ over each node
 to a flux through each vertex.
 Conversely, $L^+$ sends some definition of fluxes over the graph back to
 some heat distribution that would have induced it.
 
\end_layout

\begin_layout Standard
[picture of bidirectional mapping between heat and flux]
\begin_inset Graphics
	filename C:/Users/paul/Adv Machine Learning/heat-flux.png

\end_inset


\end_layout

\begin_layout Standard
Intuitively, if the graph is disconnected this distribution should not be
 unique, since a constant added to the distribution in each of the connected
 components will not affect the flux induced through the graph.
 Mathematically, this is affirmed by noting that $$L^+=L^{-1}$$ iff all
 eigenvalues of L are non-zero which, is exactly when the graph is connected.
\end_layout

\begin_layout Standard
With that in mind, we can intriduce the mathematical framework for the online
 larning algorithm of Herbster et.
 al.
 Herbster seeks to minimize 
\end_layout

\begin_layout Standard
XXXXXX
\end_layout

\begin_layout Standard
over the feasible set of functions, which is simply the set of functions
 that assigns approximately correct labels to all known vertices.
 This minimization can be thought of as the set of labels that minimizes
 the total flux through the graph.
 Intuitively, this objective function should depend on basic structures
 in teh graph, such as the total number of edges connecting disagreeing
 vertices, or the total diameter of the graph.
\end_layout

\begin_layout Standard
The algorithm proceeds as follows.
 We begin with an initial guess $f_1$ for our distribution, after which
 we receive the true lavel for vertex 1.
 We then project our vector onto the convex set of feasible functions, defined
 as XXXXX.
 We then use the 2nd row of the reproducing kernel $L^+$ to calculate how
 this update affects our guess for vertex 2.
 We do this by using our updated distribution to calculate the flux induced
 through all vertices in the graph by calculating $Lf_1$.
 Then using this updated flux, we calculate $L^+_2Lf_1=<L^+_2,f_1>$, which
 tells us the 2nd component of the distribution that would have produced
 this new flux.
 In other words, it is an updated guess for the value at vertex 2.
 We then receive the label for vertex 2, which defines our second feasible
 set, and we continue this process for each vertex in the online setting.
\end_layout

\begin_layout Standard
Discussion:
\end_layout

\begin_layout Standard
-differences from Jacobia algorithm and other algorithms based purely on
 the Laplacian: 
\end_layout

\begin_layout Standard
- at each round, not only are the labeled vertices used to propogate, but
 also the unlabeled ones.
\end_layout

\begin_layout Standard
- it requires a lot of memory to compute the pseudoinverse.
 This can be done as a pre-processing step, but if the graph is very large,
 this may be prohibitive in terms of space complexity.
 Special algorithms must be adapted in this case that take advantage of
 the sparsity of the Laplacian, as well as the anticipated sparsity ofthe
 pseudoinverse
\end_layout

\begin_layout Standard
\begin_inset Newpage clearpage
\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
renewcommand
\backslash
refname{Bibliography}
\end_layout

\end_inset


\begin_inset Note Comment
status open

\begin_layout Plain Layout
Leave this inside the comment:
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "bibliography"
options "plain"

\end_inset


\end_layout

\begin_layout Plain Layout
LyX still provides its citation dialogs, but does not export bibtex commands
 to LaTeX.
 Bibliography database has to be loaded twice: in the document preamble
 for biblatex, and through the above button for LyX support.
\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
nocite{*}
\end_layout

\begin_layout Plain Layout


\backslash
printbibliography
\end_layout

\begin_layout Plain Layout


\backslash
addcontentsline{toc}{chapter}{Bibliography}
\end_layout

\end_inset


\end_layout

\end_body
\end_document
